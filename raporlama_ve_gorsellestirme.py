# -*- coding: utf-8 -*-
"""
raporlama_ve_gorsellestirme.py (PoF - Ultimate Reporting Engine v3.3)
FIXES:
1. Auto-calculates 'PoF_Ensemble_12Ay' if missing.
2. Robust merging logic for Case Studies.
3. Maps 'Risk_Sinifi' to 'Risk_Class' automatically.
"""

import os
import sys
import logging
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta

# PPTX Library Check
try:
    from pptx import Presentation
    from pptx.util import Inches, Pt
    HAS_PPTX = True
except ImportError:
    HAS_PPTX = False
    print("Warning: 'python-pptx' not installed. Skipping PPTX generation.")

# --- KONFÄ°GÃœRASYON VE YOLLAR ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
OUTPUT_DIR = os.path.join(BASE_DIR, "data", "sonuclar")
INTERMEDIATE_DIR = os.path.join(BASE_DIR, "data", "ara_ciktilar")
LOG_DIR = os.path.join(BASE_DIR, "loglar")

# KlasÃ¶rlerin varlÄ±ÄŸÄ±ndan emin ol
for d in [OUTPUT_DIR, INTERMEDIATE_DIR, LOG_DIR]:
    os.makedirs(d, exist_ok=True)

# Alt KlasÃ¶rler
ACTION_DIR = os.path.join(OUTPUT_DIR, "aksiyon_listeleri")
VISUAL_DIR = os.path.join(OUTPUT_DIR, "gorseller")
REPORT_DIR = OUTPUT_DIR

for d in [ACTION_DIR, VISUAL_DIR]:
    os.makedirs(d, exist_ok=True)

# GÃ¶rsel AyarlarÄ±
plt.style.use('ggplot')
sns.set_palette("husl")
# =============================================================================
# ğŸ› ï¸ UTILITIES: LOGGING & DATA REPAIR (LOGLAMA VE VERÄ° ONARIMI)
# =============================================================================
# 1. setup_logger:
#    - Raporlama sÃ¼recinin her adÄ±mÄ±nÄ± kayÄ±t altÄ±na alÄ±r.
#    - HatalarÄ± hem ekrana basar hem dosyaya kaydeder.
#
# 2. ensure_pof_column (Hayat KurtarÄ±cÄ±):
#    - RaporlarÄ±n ana metriÄŸi 'PoF_Ensemble_12Ay' sÃ¼tunudur.
#    - EÄŸer Ã¶nceki aÅŸamada (pof.py) bu sÃ¼tun Ã¼retilemediyse (Ã¶rn. sadece tek model Ã§alÄ±ÅŸtÄ±ysa),
#      bu fonksiyon devreye girer.
#    - Mevcut diÄŸer 12 aylÄ±k tahminleri (Cox, ML vb.) bulur ve onlarÄ±n ortalamasÄ±nÄ±
#      alarak eksik sÃ¼tunu "imal eder". BÃ¶ylece raporlama Ã§Ã¶kmez.
# =============================================================================
# ------------------------------------------------------------------------------
# DATE PARSING (KARMA FORMAT DESTEÄÄ°)
# ------------------------------------------------------------------------------
def parse_mixed_dates(date_str):
    """
    Karma tarih formatlarÄ±nÄ± TR standartÄ±na (GÃœN-AY-YIL) uygun parse eder.
    Desteklenen formatlar:
    - DD-MM-YYYY HH:MM:SS (22-06-2025 04:59:21)
    - YYYY-MM-DD HH:MM:SS (2023-01-17 17:14:42)
    - DD-MM-YYYY (05-03-2025)
    """
    if pd.isna(date_str):
        return pd.NaT

    # String'e Ã§evir (sayÄ± olarak gelebilir)
    date_str = str(date_str).strip()

    # Deneme sÄ±rasÄ± (TR formatÄ± Ã¶ncelikli)
    formats = [
        '%d-%m-%Y %H:%M:%S',  # 22-06-2025 04:59:21
        '%d-%m-%Y',           # 05-03-2025
        '%Y-%m-%d %H:%M:%S',  # 2023-01-17 17:14:42
        '%Y-%m-%d',           # 2023-01-17
        '%d.%m.%Y %H:%M:%S',  # 22.06.2025 04:59:21 (NoktalÄ±)
        '%d.%m.%Y',           # 22.06.2025
    ]

    for fmt in formats:
        try:
            return pd.to_datetime(date_str, format=fmt)
        except:
            continue

    # HiÃ§biri iÅŸe yaramazsa pandas otomatik (dayfirst=True)
    try:
        return pd.to_datetime(date_str, dayfirst=True)
    except:
        return pd.NaT

# ------------------------------------------------------------------------------
# LOGGING
# ------------------------------------------------------------------------------
def setup_logger():
    os.makedirs(LOG_DIR, exist_ok=True)
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    logger = logging.getLogger("Raporlama")
    logger.setLevel(logging.INFO)
    logger.handlers.clear()
    
    fh = logging.FileHandler(os.path.join(LOG_DIR, f"raporlama_{ts}.log"), encoding="utf-8")
    fh.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))
    logger.addHandler(fh)
    logger.addHandler(logging.StreamHandler(sys.stdout))
    return logger

# ------------------------------------------------------------------------------
# HELPER: ENSURE POF COLUMN EXISTS
# ------------------------------------------------------------------------------
def ensure_pof_column(df, logger):
    """
    'PoF_Ensemble_12Ay' kolonunu kontrol eder, yoksa hesaplar.
    """
    target = 'PoF_Ensemble_12Ay'
    
    if target in df.columns:
        return df
    
    logger.warning(f"  [FIX] '{target}' eksik. BileÅŸenlerden hesaplanmaya Ã§alÄ±ÅŸÄ±lÄ±yor...")
    
    # OlasÄ± PoF kolonlarÄ±nÄ± bul
    candidates = [c for c in df.columns if ('_pof_12' in c.lower()) or ('_12ay' in c.lower() and 'pof' in c.lower())]
    candidates = [c for c in candidates if c != target]
    
    if candidates:
        logger.info(f"  [FIX] Bulunan bileÅŸenler: {candidates}")
        df[target] = df[candidates].mean(axis=1)
        logger.info(f"  [FIX] '{target}' kolonu {len(candidates)} modelin ortalamasÄ± ile oluÅŸturuldu.")
    else:
        logger.warning("  [FAIL] 12 aylÄ±k PoF bileÅŸeni bulunamadÄ±. Dummy (0.0) oluÅŸturuluyor.")
        df[target] = 0.0
        
    return df

# ------------------------------------------------------------------------------
# PHASE 1: ACTION PLANNING
# ------------------------------------------------------------------------------
# =============================================================================
# ğŸ“‹ ACTIONABLE INTELLIGENCE (AKSÄ°YON LÄ°STELERÄ°)
# =============================================================================
# Bu fonksiyon, matematiksel sonuÃ§larÄ± "Sahada YapÄ±lacak Ä°ÅŸlere" dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
#
# 1. ğŸš¨ Acil MÃ¼dahale (Priority 1):
#    - Hem "Kronik" (SÃ¼rekli bozulan) hem de "Kritik Risk" (Ã–mrÃ¼nÃ¼ tamamlamÄ±ÅŸ) varlÄ±klar.
#    - Aksiyon: Derhal yerinde inceleme veya deÄŸiÅŸim.
#
# 2. ğŸ’° CAPEX / YatÄ±rÄ±m (Priority 2):
#    - Ã–zellikle Trafolar gibi pahalÄ± ve tedariÄŸi uzun sÃ¼ren ekipmanlar.
#    - YÃ¼ksek riskli trafolar belirlenip, gelecek yÄ±lÄ±n bÃ¼tÃ§esine deÄŸiÅŸim olarak girmeli.
#
# 3. ğŸ” FÄ±rsat BakÄ±mÄ± / OPEX (Priority 3):
#    - Model diyor ki: "Bu varlÄ±k henÃ¼z Kritik sÄ±nÄ±fa girmedi (belki yaÅŸÄ± genÃ§),
#      AMA Ã¶nÃ¼mÃ¼zdeki 12 ay iÃ§inde bozulma ihtimali yÃ¼kseliyor (%15+)."
#    - Aksiyon: Ã–nleyici bakÄ±m (Termal kamera, yaÄŸ analizi) ile kurtarÄ±labilir.
# =============================================================================
def generate_action_lists(df, logger):
    """
    Operasyonel aksiyon listelerini (CSV) oluÅŸturur.
    BakÄ±m ekipleri iÃ§in okunabilir, temiz raporlar Ã¼retir.
    """
    logger.info("="*60)
    logger.info("[PHASE 1] Aksiyon Listeleri OluÅŸturuluyor...")
    
    # 1. Kolon Standardizasyonu (Defensive Coding)
    risk_col = 'Risk_Sinifi'
    if 'Risk_Class' in df.columns: risk_col = 'Risk_Class'
    
    chronic_col = 'Chronic_Flag'
    if 'Kronik_Flag' in df.columns: chronic_col = 'Kronik_Flag' # Manuel deÄŸiÅŸim varsa yakala

    # 2. Raporlarda GÃ¶rÃ¼necek Temiz SÃ¼tunlar (Human-Readable)
    # BakÄ±mcÄ±nÄ±n iÅŸine yaramayan VIF skorlarÄ±nÄ±, one-hot sÃ¼tunlarÄ±nÄ± rapora koymuyoruz.
    report_cols = [
        "cbs_id", "Ekipman_Tipi", "Ilce", "Mahalle", "Marka",
        "Kurulum_Tarihi", "Gerilim_Seviyesi", 
        "Health_Score", risk_col, "PoF_Ensemble_12Ay", 
        chronic_col, "Ariza_Sayisi_90g"
    ]
    # Sadece veride var olanlarÄ± seÃ§
    final_cols = [c for c in report_cols if c in df.columns]

    # --- LÄ°STE 1: ACÄ°L MÃœDAHALE (Kritik + Kronik) ---
    # Hem Ã§ok riskli hem de sÃ¼rekli arÄ±za yapÄ±yor. Hemen bakÄ±lmalÄ±.
    if chronic_col in df.columns:
        crit_chronic = df[
            (df[risk_col].isin(['Critical', 'KRÄ°TÄ°K', 'KRÄ°TÄ°K (KRONÄ°K)'])) & 
            (df[chronic_col] == 1)
        ].copy()
    else:
        crit_chronic = pd.DataFrame()
    
    if not crit_chronic.empty:
        # En riskliden aza doÄŸru sÄ±rala
        crit_chronic = crit_chronic.sort_values("PoF_Ensemble_12Ay", ascending=False)
        
        path = os.path.join(ACTION_DIR, "01_ACIL_MUDHALE_LISTESI_Kronik.csv")
        crit_chronic[final_cols].to_csv(path, index=False, encoding='utf-8-sig')
        logger.info(f"  ğŸš¨ [ACÄ°L] Kronik & Kritik: {len(crit_chronic)} varlÄ±k (Dosya: 01_...)")
    else:
        logger.info("  âœ… [ACÄ°L] Kronik ve Kritik varlÄ±k bulunamadÄ±.")

    # --- LÄ°STE 2: YÃœKSEK RÄ°SKLÄ° TRAFOLAR (CAPEX YatÄ±rÄ±m PlanÄ±) ---
    # Trafolar pahalÄ±dÄ±r. YÃ¼ksek riskli olanlarÄ±n deÄŸiÅŸimi bÃ¼tÃ§elenmeli.
    trafos = df[
        (df['Ekipman_Tipi'].astype(str).str.contains('Trafo', case=False, na=False)) & 
        (df[risk_col].isin(['Critical', 'High', 'KRÄ°TÄ°K', 'YÃœKSEK', 'KRÄ°TÄ°K (KRONÄ°K)']))
    ].copy()
    
    if not trafos.empty:
        trafos = trafos.sort_values("Health_Score", ascending=True) # En dÃ¼ÅŸÃ¼k puan en Ã¼stte
        path = os.path.join(ACTION_DIR, "02_YATIRIM_PLANLAMA_Riskli_Trafolar.csv")
        trafos[final_cols].to_csv(path, index=False, encoding='utf-8-sig')
        logger.info(f"  ğŸ’° [CAPEX] YÃ¼ksek Riskli Trafolar: {len(trafos)} varlÄ±k")

    # --- LÄ°STE 3: Ä°ÅLETME KONTROL (FÄ±rsat BakÄ±mÄ± / Quick Wins) ---
    # Risk sÄ±nÄ±fÄ± henÃ¼z 'Kritik' deÄŸil ama Bozulma Ä°htimali (PoF) artmaya baÅŸlamÄ±ÅŸ.
    # "HenÃ¼z yangÄ±n Ã§Ä±kmadÄ± ama duman tÃ¼tÃ¼yor" listesi.
    if 'PoF_Ensemble_12Ay' in df.columns:
        inspection = df[
            (df['PoF_Ensemble_12Ay'] > 0.15) &  # %15 Ã¼zeri ihtimal
            (df[risk_col].isin(['Low', 'Medium', 'DÃœÅÃœK', 'ORTA'])) # Ama sÄ±nÄ±fÄ± dÃ¼ÅŸÃ¼k
        ].copy()
        
        if not inspection.empty:
            inspection = inspection.sort_values('PoF_Ensemble_12Ay', ascending=False)
            path = os.path.join(ACTION_DIR, "03_ISLETME_KONTROL_Firsat_Bakimi.csv")
            inspection[final_cols].to_csv(path, index=False, encoding='utf-8-sig')
            logger.info(f"  ğŸ” [OPEX] FÄ±rsat BakÄ±mÄ± (YÃ¼ksek OlasÄ±lÄ±k/DÃ¼ÅŸÃ¼k Risk): {len(inspection)} varlÄ±k")

    return crit_chronic # Dashboard iÃ§in kritik listeyi dÃ¶ndÃ¼r

# ------------------------------------------------------------------------------
# PHASE 2: VISUALIZATION
# ------------------------------------------------------------------------------
# =============================================================================
# ğŸ“Š VISUALIZATION & REALITY CHECK (GÃ–RSELLEÅTÄ°RME VE DOÄRULAMA)
# =============================================================================
# Bu modÃ¼l, karmaÅŸÄ±k model Ã§Ä±ktÄ±larÄ±nÄ± (olasÄ±lÄ±klar, katsayÄ±lar) yÃ¶neticilerin
# anlayabileceÄŸi gÃ¶rsel iÃ§gÃ¶rÃ¼lere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r ve modelin "akÄ±l saÄŸlÄ±ÄŸÄ±nÄ±" test eder.
#
# 1. ğŸŒ CoÄŸrafi Risk HaritasÄ± (generate_visuals):
#    - Risklerin mekansal daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶sterir.
#    - "Hangi ilÃ§ede veya ÅŸebeke kolunda risk birikmiÅŸ?" sorusuna cevap verir.
#
# 2. ğŸ§ª Kalibrasyon & Validasyon (validate_base_rates):
#    - EN KRÄ°TÄ°K GÃœVENLÄ°K ADIMIDIR.
#    - Modelin sonuÃ§larÄ±nÄ± CIGRE/IEEE endÃ¼stri standartlarÄ±yla kÄ±yaslar.
#    - Ã–rnek: EÄŸer model TrafolarÄ±n %50'sinin seneye bozulacaÄŸÄ±nÄ± sÃ¶ylÃ¼yorsa,
#      bu fonksiyon "HATA: EndÃ¼stri standardÄ± %2-5 arasÄ±dÄ±r, model aÅŸÄ±rÄ± kÃ¶tÃ¼mser!"
#      diye uyarÄ±r. Bu, "Model HalÃ¼sinasyonunu" engeller.
#
# 3. ğŸ“ˆ Stratejik AyrÄ±m (plot_aggregate_risk_by_type):
#    - Ã‡ift Eksenli Grafik (Dual-Axis):
#      a. Bar (Sol): YaÅŸlanma/YÄ±pranma Riski (PoF).
#      b. Ã‡izgi (SaÄŸ): Kronik/Operasyonel Sorunlar.
#    - Bu ayrÄ±m, yatÄ±rÄ±mÄ±n nereye yapÄ±lacaÄŸÄ±nÄ± (Yeni cihaz mÄ±? Tamir mi?) belirler.
# =============================================================================
def plot_single_chart(df, col_x, col_y, plot_type, title, filename, logger, **kwargs):
    """
    Genel amaÃ§lÄ±, hata korumalÄ± grafik Ã§izim fonksiyonu.
    """
    width = kwargs.pop('width', 10)
    height = kwargs.pop('height', 6)
    
    plt.figure(figsize=(width, height))
    
    try:
        if plot_type == 'scatter':
            sns.scatterplot(data=df, x=col_x, y=col_y, **kwargs)
        elif plot_type == 'hist':
            sns.histplot(df[col_x], kde=True, **kwargs)
        elif plot_type == 'bar':
            sns.barplot(x=col_x, y=col_y, data=df, **kwargs)

        plt.title(title, fontsize=14, fontweight='bold')
        plt.tight_layout()
        path = os.path.join(VISUAL_DIR, filename)
        plt.savefig(path, dpi=300, bbox_inches='tight')
        plt.close()
        logger.info(f"  ğŸ“¸ Grafik oluÅŸturuldu: {filename}")
        return path
    except Exception as e:
        logger.error(f"  âŒ [ERROR] Grafik Ã§izilemedi ({filename}): {str(e)}")
        plt.close()
        return None
# ------------------------------------------------------------------------------
# PHASE 2.5: ADVANCED DIAGNOSTICS (SÄ°ZÄ°N GÃ–RSELLERÄ°NÄ°Z)
# ------------------------------------------------------------------------------

def plot_risk_drivers(df_model, logger):
    """
    GÃ–RSEL 1: Risk FaktÃ¶rleri (Korelasyon Analizi)
    Veri KaynaÄŸÄ±: model_input_data_full.csv (pof.py ara Ã§Ä±ktÄ±sÄ±)
    """
    logger.info("[ADVANCED] Risk FaktÃ¶rleri (Drivers) analiz ediliyor...")
    
    # SayÄ±sal kolonlarÄ± seÃ§
    num_cols = df_model.select_dtypes(include=[np.number]).columns
    if 'event' not in num_cols: return None

    # Korelasyon hesapla (Target: event)
    corrs = df_model[num_cols].corrwith(df_model['event']).sort_values(ascending=False)
    
    # En etkili 10 faktÃ¶r (Kendisi hariÃ§)
    top_drivers = corrs.drop('event', errors='ignore').head(5)
    bottom_drivers = corrs.drop('event', errors='ignore').tail(5)
    drivers = pd.concat([top_drivers, bottom_drivers]).sort_values()

    plt.figure(figsize=(10, 6))
    colors = ['green' if x < 0 else 'red' for x in drivers.values]
    drivers.plot(kind='barh', color=colors, edgecolor='black', alpha=0.8)
    
    plt.title('Risk FaktÃ¶rleri (Drivers) - ArÄ±za ile Korelasyon', fontsize=16)
    plt.xlabel('Korelasyon KatsayÄ±sÄ± (SaÄŸ taraf risk arttÄ±rÄ±cÄ±)', fontsize=10)
    plt.grid(True, linestyle='--', alpha=0.5)
    
    path = os.path.join(VISUAL_DIR, "ADV_01_Risk_Drivers.png")
    plt.savefig(path, dpi=300, bbox_inches='tight')
    plt.close()
    return path

def plot_operational_dashboard(logger):
    """
    GÃ–RSEL 2: Operasyonel Durum (4'lÃ¼ Dashboard)
    Veri KaynaÄŸÄ±: fault_events_clean.csv
    """
    path = os.path.join(INTERMEDIATE_DIR, "fault_events_clean.csv")
    if not os.path.exists(path): return None
    
    df = pd.read_csv(path)
    df['started at'] = df['started at'].apply(parse_mixed_dates)

    # Gelecek tarihli kayÄ±tlarÄ± filtrele
    today = pd.Timestamp.now()
    df = df[df['started at'] <= today]

    fig, axes = plt.subplots(2, 2, figsize=(16, 10))
    fig.suptitle('Operasyonel Durum Paneli', fontsize=24)
    
    # 1. AylÄ±k ArÄ±za Trendi
    df['Ay'] = df['started at'].dt.to_period('M')
    monthly = df.groupby('Ay').size()
    monthly.index = monthly.index.astype(str)
    axes[0, 0].plot(monthly.index, monthly.values, marker='o', linestyle='-', color='steelblue')
    axes[0, 0].set_title('AylÄ±k ArÄ±za Trendi')
    axes[0, 0].tick_params(axis='x', rotation=45)
    # X eksenini seyrelt
    axes[0, 0].set_xticks(axes[0, 0].get_xticks()[::3])

    # 2. En Ã‡ok ArÄ±zalanan Ekipmanlar
    top_eq = df['Ekipman_Tipi'].value_counts().head(5)
    sns.barplot(y=top_eq.index, x=top_eq.values, ax=axes[0, 1], palette='Oranges_r')
    axes[0, 1].set_title('En Ã‡ok ArÄ±zalanan Ekipmanlar')

    # 3. HaftalÄ±k YoÄŸunluk (Heatmap yerine Line/Area)
    df['Hafta'] = df['started at'].dt.isocalendar().week
    weekly = df.groupby('Hafta').size()
    axes[1, 0].fill_between(weekly.index, weekly.values, color='lightcoral', alpha=0.5)
    axes[1, 0].plot(weekly.index, weekly.values, color='red')
    axes[1, 0].set_title('HaftalÄ±k ArÄ±za YoÄŸunluÄŸu (Mevsimsellik)')

    # 4. Saatlik DaÄŸÄ±lÄ±m
    df['Saat'] = df['started at'].dt.hour
    hourly = df.groupby('Saat').size()
    sns.barplot(x=hourly.index, y=hourly.values, ax=axes[1, 1], color='purple')
    axes[1, 1].set_title('Saatlik ArÄ±za DaÄŸÄ±lÄ±mÄ±')

    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    out_path = os.path.join(VISUAL_DIR, "ADV_02_Operasyonel_Durum.png")
    plt.savefig(out_path, dpi=300)
    plt.close()
    return out_path

def plot_survival_curves(df_model, logger):
    """
    GÃ–RSEL 3: Ã–mÃ¼r EÄŸrileri (Kaplan-Meier)
    Veri KaynaÄŸÄ±: model_input_data_full.csv
    """
    try:
        from lifelines import KaplanMeierFitter
    except ImportError:
        return None

    plt.figure(figsize=(10, 6))
    kmf = KaplanMeierFitter()
    
    # En popÃ¼ler 4 ekipman tipi
    top_types = df_model['Ekipman_Tipi'].value_counts().head(4).index
    
    for etype in top_types:
        subset = df_model[df_model['Ekipman_Tipi'] == etype]
        kmf.fit(subset['duration_days'], event_observed=subset['event'], label=etype)
        kmf.plot(ci_show=False)

    plt.title('VarlÄ±k Ã–mÃ¼r EÄŸrileri (Survival Curves)', fontsize=16)
    plt.xlabel('GÃ¼n (Timeline)')
    plt.ylabel('Hayatta Kalma OlasÄ±lÄ±ÄŸÄ± S(t)')
    plt.grid(True, linestyle='--', alpha=0.5)
    
    path = os.path.join(VISUAL_DIR, "ADV_03_Omur_Egrileri.png")
    plt.savefig(path, dpi=300)
    plt.close()
    return path

def plot_health_dashboard(df_res, logger):
    """
    GÃ–RSEL 4: SaÄŸlÄ±k Analizi (Composite Dashboard)
    Veri KaynaÄŸÄ±: pof_predictions_final.csv
    """
    fig = plt.figure(figsize=(14, 8))
    gs = fig.add_gridspec(2, 2)
    fig.suptitle('SaÄŸlÄ±k Analizi Dashboard', fontsize=22)

    # 1. SaÄŸlÄ±k Skoru DaÄŸÄ±lÄ±mÄ± (Histogram)
    ax1 = fig.add_subplot(gs[0, 0])
    sns.histplot(df_res['Health_Score'], bins=30, kde=True, color='green', ax=ax1)
    ax1.axvline(x=40, color='red', linestyle='--', label='Kritik EÅŸik (40)')
    ax1.set_title('SaÄŸlÄ±k Skoru DaÄŸÄ±lÄ±mÄ±')
    ax1.legend()

    # 2. Tip BazlÄ± Ortalama SaÄŸlÄ±k (Bar)
    ax2 = fig.add_subplot(gs[0, 1])
    avg_health = df_res.groupby('Ekipman_Tipi')['Health_Score'].mean().sort_values().head(8)
    sns.barplot(y=avg_health.index, x=avg_health.values, ax=ax2, palette='RdYlGn')
    ax2.set_title('En DÃ¼ÅŸÃ¼k SaÄŸlÄ±k Skoruna Sahip Tipler')
    ax2.set_xlim(0, 100)

    # 3. Risk SÄ±nÄ±fÄ± Pasta GrafiÄŸi
    ax3 = fig.add_subplot(gs[1, 0])
    risk_col = 'Risk_Class' if 'Risk_Class' in df_res.columns else 'Risk_Sinifi'
    counts = df_res[risk_col].value_counts()
    
    # Renkleri sabitle
    colors = {'Low': '#66b3ff', 'DÃœÅÃœK': '#66b3ff', 
              'Medium': '#ffcc99', 'ORTA': '#ffcc99',
              'High': '#ff9999', 'YÃœKSEK': '#ff9999',
              'Critical': '#ff0000', 'KRÄ°TÄ°K': '#ff0000'}
    pie_colors = [colors.get(x, 'grey') for x in counts.index]
    
    ax3.pie(counts, labels=counts.index, autopct='%1.1f%%', colors=pie_colors, startangle=140)
    ax3.set_title('Risk SÄ±nÄ±fÄ± DaÄŸÄ±lÄ±mÄ±')

    # 4. BoÅŸ Alan (Veya Metin Ã–zeti)
    ax4 = fig.add_subplot(gs[1, 1])
    ax4.axis('off')
    summary_text = (
        f"Toplam VarlÄ±k: {len(df_res):,}\n"
        f"Ortalama SaÄŸlÄ±k: {df_res['Health_Score'].mean():.1f}\n"
        f"Kritik VarlÄ±klar: {counts.get('KRÄ°TÄ°K', 0) + counts.get('Critical', 0)}\n\n"
        "Not: KÄ±rmÄ±zÄ± bÃ¶lge acil aksiyon gerektirir."
    )
    ax4.text(0.1, 0.5, summary_text, fontsize=14, bbox=dict(facecolor='wheat', alpha=0.3))

    path = os.path.join(VISUAL_DIR, "ADV_04_Saglik_Analizi.png")
    plt.savefig(path, dpi=300)
    plt.close()
    return path
def generate_visuals(df, logger):
    """
    TÃ¼m gÃ¶rsel panolarÄ± (Dashboard elementleri) oluÅŸturur.
    """
    logger.info("="*60)
    logger.info("[PHASE 2] GÃ¶rsel Panolar OluÅŸturuluyor...")
    charts = {}
    
    # Risk Kolonunu Belirle (StandartlaÅŸtÄ±rma)
    risk_col = 'Risk_Sinifi'
    if 'Risk_Class' in df.columns: risk_col = 'Risk_Class'

    # 1. SAÄLIK SKORU DAÄILIMI (Histogram)
    # Filonun genel saÄŸlÄ±k durumunu gÃ¶sterir.
    if 'Health_Score' in df.columns:
        path = plot_single_chart(df, 'Health_Score', None, 'hist', 
                                 'VarlÄ±k SaÄŸlÄ±k Skoru DaÄŸÄ±lÄ±mÄ± (0=Ã–lÃ¼, 100=MÃ¼kemmel)', 
                                 "02_saglik_skoru_dagilimi.png", logger,
                                 bins=40, color='teal', edgecolor='black')
        charts['health_dist'] = path

    # 2. KRONÄ°K ANALÄ°ZÄ° (Bar Chart)
    # Hangi ekipmanlar sÃ¼rekli baÅŸ aÄŸrÄ±tÄ±yor?
    chronic_col = 'Chronic_Flag' if 'Chronic_Flag' in df.columns else 'Kronik_Flag'
    
    if chronic_col in df.columns:
        counts = df[chronic_col].value_counts()
        plt.figure(figsize=(8, 6))
        # 0: YeÅŸil (Normal), 1: KÄ±rmÄ±zÄ± (Kronik)
        colors = ['green', 'red'] if len(counts) == 2 else ['green']
        
        counts.plot(kind='bar', color=colors, edgecolor='black', alpha=0.8)
        plt.title('Kronik VarlÄ±k DaÄŸÄ±lÄ±mÄ± (1 = Kronik Sorunlu)', fontsize=14)
        plt.xlabel("Durum (0: Normal, 1: Kronik)")
        plt.ylabel("VarlÄ±k SayÄ±sÄ±")
        plt.xticks(rotation=0)
        
        path = os.path.join(VISUAL_DIR, "03_kronik_dagilimi.png")
        plt.savefig(path, dpi=300, bbox_inches='tight')
        plt.close()
        charts['chronic_dist'] = path

    # 3. COÄRAFÄ° HARÄ°TA (Scatter Plot)
    # Risklerin mekansal daÄŸÄ±lÄ±mÄ±.
    if 'Latitude' in df.columns and 'Longitude' in df.columns:
        # KoordinatÄ± 0 olmayanlarÄ± al (Veri temizliÄŸi)
        gdf = df[(df['Latitude'] != 0) & (df['Longitude'] != 0) & (df['Latitude'].notna())].copy()
        
        if not gdf.empty:
            # Renk HaritasÄ± (Risk SÄ±nÄ±fÄ±na GÃ¶re)
            palette_map = {
                'Critical': 'red', 'High': 'orange', 'Medium': 'gold', 'Low': 'green',
                'KRÄ°TÄ°K': 'red', 'KRÄ°TÄ°K (KRONÄ°K)': 'purple', 'YÃœKSEK': 'orange', 
                'ORTA': 'gold', 'DÃœÅÃœK': 'green'
            }
            
            # Haritada olmayan etiketleri gri yap
            for label in gdf[risk_col].unique():
                if label not in palette_map: palette_map[label] = 'gray'

            path = plot_single_chart(gdf, 'Longitude', 'Latitude', 'scatter', 
                                     'CoÄŸrafi Risk HaritasÄ±', "04_cografi_risk_haritasi.png", logger,
                                     hue=risk_col, height=10, width=10,
                                     palette=palette_map, s=40, alpha=0.7, edgecolor='k')
            charts['geo_map'] = path

    return charts

def validate_base_rates(df, logger):
    """
    Modelin sonuÃ§larÄ±nÄ± EndÃ¼stri StandartlarÄ± ile kÄ±yaslar (Reality Check).
    """
    logger.info("="*60)
    logger.info("[VALIDATION] Model Kalibrasyon KontrolÃ¼...")
    
    # SektÃ¶r beklentileri (YÄ±llÄ±k ArÄ±za OranÄ± - Failure Rate)
    # Kaynak: CIGRE ve IEEE standartlarÄ± (yaklaÅŸÄ±k)
    INDUSTRY_RANGES = {
        'Trafo': (0.005, 0.05),   # %0.5 - %5 arasÄ± normal
        'Kesici': (0.01, 0.08),   # %1 - %8
        'AyÄ±rÄ±cÄ±': (0.02, 0.12),  # AyÄ±rÄ±cÄ±lar daha sÄ±k bozulur
        'Sigorta': (0.10, 0.40),  # Sigortalar sarf malzemesidir, Ã§ok bozulur
        'Hat': (0.005, 0.15),     # Hava ÅŸartlarÄ±na baÄŸlÄ±
        'Direk': (0.001, 0.03)    # Direkler nadir yÄ±kÄ±lÄ±r
    }
    
    target_col = 'PoF_Ensemble_12Ay'
    if target_col not in df.columns:
        logger.warning("  âš ï¸ [SKIP] PoF kolonu yok. Validasyon yapÄ±lamÄ±yor.")
        return

    # Ekipman tipine gÃ¶re ortalama tahminleri al
    stats = df.groupby('Ekipman_Tipi')[target_col].mean().reset_index()
    
    for _, row in stats.iterrows():
        etype = str(row['Ekipman_Tipi'])
        pred = row[target_col]
        
        # Ekipman isminde anahtar kelime ara (Ã¶rn: "OG Trafo" iÃ§inde "Trafo" var mÄ±?)
        matched_key = next((k for k in INDUSTRY_RANGES if k in etype), None)
        
        if matched_key:
            low, high = INDUSTRY_RANGES[matched_key]
            status = "âœ… OK"
            if pred < low: status = "ğŸ“‰ DÃœÅÃœK (Under-prediction?)"
            if pred > high: status = "ğŸš¨ YÃœKSEK (Over-prediction?)"
            
            logger.info(f"  > {etype.ljust(25)}: Tahmin %{pred*100:.1f} (Ref: %{low*100:.0f}-%{high*100:.0f}) -> {status}")

def plot_aggregate_risk_by_type(df, logger):
    """
    Ekipman tiplerine gÃ¶re risk yoÄŸunluÄŸunu gÃ¶steren Dual-Axis grafik.
    """
    if 'PoF_Ensemble_12Ay' not in df.columns:
        return None

    # Agregasyon
    # Hangi sÃ¼tun adÄ±nÄ± kullanacaÄŸÄ±mÄ±zÄ± bulalÄ±m
    chronic_col = 'Chronic_Flag' if 'Chronic_Flag' in df.columns else 'Kronik_Flag'
    
    agg_dict = {'PoF_Ensemble_12Ay': 'mean', 'cbs_id': 'count'}
    if chronic_col in df.columns:
        agg_dict[chronic_col] = 'mean' # Kronik oranÄ±

    agg_df = df.groupby('Ekipman_Tipi').agg(agg_dict).reset_index()
    
    # SÃ¼tun isimlerini dÃ¼zelt
    agg_df = agg_df.rename(columns={
        'PoF_Ensemble_12Ay': 'Mean_PoF', 
        'cbs_id': 'Count',
        chronic_col: 'Chronic_Rate'
    })
    
    # Sadece en az 30 varlÄ±ÄŸÄ± olan tipleri al ve en risklileri seÃ§
    agg_df = agg_df[agg_df['Count'] >= 30].sort_values('Mean_PoF', ascending=False).head(10)

    if agg_df.empty: return None

    # Ã‡ift Eksenli Grafik Ã‡izimi
    fig, ax1 = plt.subplots(figsize=(12, 6))
    
    # 1. Bar Chart (ArÄ±za OlasÄ±lÄ±ÄŸÄ±)
    sns.barplot(x='Ekipman_Tipi', y='Mean_PoF', data=agg_df, ax=ax1, color='firebrick', alpha=0.6)
    ax1.set_ylabel('Ortalama ArÄ±za OlasÄ±lÄ±ÄŸÄ± (12 Ay)', color='firebrick', fontweight='bold')
    ax1.tick_params(axis='y', labelcolor='firebrick')
    ax1.set_xlabel('Ekipman Tipi', fontsize=12)
    ax1.tick_params(axis='x', rotation=45)
    
    # 2. Line Chart (Kronik OranÄ±) - EÄŸer veri varsa
    if 'Chronic_Rate' in agg_df.columns:
        ax2 = ax1.twinx()
        sns.lineplot(x='Ekipman_Tipi', y='Chronic_Rate', data=agg_df, ax=ax2, color='navy', marker='o', linewidth=2)
        ax2.set_ylabel('Kronik VarlÄ±k OranÄ±', color='navy', fontweight='bold')
        ax2.tick_params(axis='y', labelcolor='navy')
        ax2.grid(False) # Ä°kinci Ä±zgarayÄ± kapat ki karÄ±ÅŸmasÄ±n
    
    plt.title('Ekipman Tipine GÃ¶re Risk Analizi (Top 10)', fontsize=14)
    
    path = os.path.join(VISUAL_DIR, "08_aggregate_risk_by_type.png")
    plt.savefig(path, dpi=300, bbox_inches='tight')
    plt.close()
    
    logger.info(f"  ğŸ“¸ Karma risk grafiÄŸi kaydedildi: 08_aggregate_risk_by_type.png")
    return path
# ------------------------------------------------------------------------------
# PHASE 3: EXCEL REPORTING
# ------------------------------------------------------------------------------

def generate_case_studies(df_risk, logger):
    """
    Modelin son 6 aydaki baÅŸarÄ±sÄ±nÄ± Ã¶lÃ§en 'Vaka Analizi' (Case Study) tablosu.
    """
    logger.info("[PHASE 1.5] Vaka Analizleri (Case Studies) OluÅŸturuluyor...")
    
    # 1. ArÄ±za OlaylarÄ±nÄ± YÃ¼kle
    events_path = os.path.join(INTERMEDIATE_DIR, "fault_events_clean.csv")
    
    events = pd.DataFrame()
    if os.path.exists(events_path):
        events = pd.read_csv(events_path)
        logger.info(f"  > ArÄ±za verisi yÃ¼klendi: {events_path}")
    else:
        raw_path = os.path.join(BASE_DIR, "data", "girdiler", "ariza_final.xlsx")
        if os.path.exists(raw_path):
            logger.warning("  âš ï¸ Ara Ã§Ä±ktÄ± yok, ham Excel okunuyor...")
            events = pd.read_excel(raw_path)
    
    if events.empty:
        logger.error("  âŒ ArÄ±za verisi bulunamadÄ±. Case Study atlanÄ±yor.")
        return pd.DataFrame()

    # 2. SÃ¼tun Ä°simlerini StandartlaÅŸtÄ±r
    col_map = {
        'started at': 'Ariza_Baslangic_Zamani',
        'cbs_id': 'cbs_id',
        'Ekipman Kodu': 'cbs_id'
    }
    events = events.rename(columns=col_map)
    
    if 'Ariza_Baslangic_Zamani' not in events.columns or 'cbs_id' not in events.columns:
        logger.error("  âŒ Gerekli sÃ¼tunlar (started at, cbs_id) eksik.")
        return pd.DataFrame()

    # 3. Tarih ve ID TemizliÄŸi
    # parse_mixed_dates fonksiyonunun import edildiÄŸinden emin olun, yoksa pd.to_datetime kullanÄ±n
    try:
        events['Ariza_Baslangic_Zamani'] = events['Ariza_Baslangic_Zamani'].apply(parse_mixed_dates)
    except NameError:
        events['Ariza_Baslangic_Zamani'] = pd.to_datetime(events['Ariza_Baslangic_Zamani'], errors='coerce')

    events['cbs_id'] = events['cbs_id'].astype(str).str.lower().str.strip()

    # 3.5. Gelecek Tarihli KayÄ±tlarÄ± Filtrele
    today = pd.Timestamp.now()
    future_count = (events['Ariza_Baslangic_Zamani'] > today).sum()
    if future_count > 0:
        logger.warning(f"  âš ï¸ {future_count} gelecek tarihli kayÄ±t bulundu ve filtrelendi.")
        events = events[events['Ariza_Baslangic_Zamani'] <= today]

    # 4. Son 6 Aydaki ArÄ±zalarÄ± Filtrele
    last_date = events['Ariza_Baslangic_Zamani'].max()
    if pd.isna(last_date): return pd.DataFrame()
    
    cutoff_date = last_date - timedelta(days=180)
    
    # [DÃœZELTME BURADA] - DeÄŸiÅŸken ismi tutarlÄ±lÄ±ÄŸÄ± saÄŸlandÄ±
    recent_faults = events[events['Ariza_Baslangic_Zamani'] >= cutoff_date].copy()
    
    # Sadece gerekli sÃ¼tunlarÄ± al, bÃ¶ylece 'Ekipman_Tipi' gibi sÃ¼tunlar buradan silinir
    # ve merge iÅŸleminde Ã§akÄ±ÅŸma (duplicate column) yaratmaz.
    keep_cols = ['cbs_id', 'Ariza_Baslangic_Zamani', 'cause code', 'Ariza_Nedeni']
    recent_faults = recent_faults[[c for c in keep_cols if c in recent_faults.columns]]

    if recent_faults.empty:
        logger.warning("  âš ï¸ Son 6 ayda hiÃ§ arÄ±za kaydÄ± yok.")
        return pd.DataFrame()

    # 5. Risk Verisi ile BirleÅŸtir (Merge)
    df_risk = ensure_pof_column(df_risk, logger)
    df_risk['cbs_id'] = df_risk['cbs_id'].astype(str).str.lower().str.strip()

    risk_col = 'Risk_Sinifi'
    if 'Risk_Class' in df_risk.columns: risk_col = 'Risk_Class'
    
    # Ekipman_Tipi burada ekleniyor (df_risk'ten geliyor)
    cols_to_merge = ['cbs_id', risk_col, 'PoF_Ensemble_12Ay', 'Health_Score', 'Ekipman_Tipi', 'Ilce', 'Marka']
    cols_to_merge = [c for c in cols_to_merge if c in df_risk.columns]

    # [DÃœZELTME] merge iÅŸleminde temizlenmiÅŸ 'recent_faults' kullanÄ±lÄ±yor
    case_df = recent_faults.merge(df_risk[cols_to_merge], on='cbs_id', how='left')
    
    # 6. BaÅŸarÄ± DeÄŸerlendirmesi
    def judge_prediction(row):
        if risk_col not in row or pd.isna(row[risk_col]): return "Bilinmeyen VarlÄ±k"
        
        r = str(row[risk_col]).upper()
        if any(x in r for x in ['CRIT', 'KRÄ°T', 'HIGH', 'YÃœKSEK']):
            return "BAÅARILI (Ã–ngÃ¶rÃ¼ldÃ¼)"
        elif any(x in r for x in ['MED', 'ORTA']):
            return "KISMÄ° (Ä°zleme)"
        else:
            return "KAÃ‡IRILDI (DÃ¼ÅŸÃ¼k Risk)"

    case_df['Model_Karari'] = case_df.apply(judge_prediction, axis=1)
    
    # Rapor iÃ§in SeÃ§im
    successes = case_df[case_df['Model_Karari'] == "BAÅARILI (Ã–ngÃ¶rÃ¼ldÃ¼)"].sort_values('Ariza_Baslangic_Zamani', ascending=False).head(10)
    misses = case_df[case_df['Model_Karari'] == "KAÃ‡IRILDI (DÃ¼ÅŸÃ¼k Risk)"].sort_values('Ariza_Baslangic_Zamani', ascending=False).head(5)
    
    final_cases = pd.concat([successes, misses])
    
    # SÃ¼tun SÄ±ralamasÄ± (GÃ¶rsel GÃ¼zellik Ä°Ã§in)
    display_order = ['cbs_id', 'Ekipman_Tipi', 'Ariza_Baslangic_Zamani', 'Ilce', 'Model_Karari', risk_col, 'PoF_Ensemble_12Ay']
    final_cols = [c for c in display_order if c in final_cases.columns]
    final_cases = final_cases[final_cols]

    logger.info(f"  âœ… Vaka analizi tamamlandÄ±: {len(successes)} BaÅŸarÄ±lÄ±, {len(misses)} KaÃ§Ä±rÄ±lan Ã¶rnek seÃ§ildi.")
    
    return final_cases

# ------------------------------------------------------------------------------
# PHASE 3: EXCEL REPORTING (FINAL OUTPUT)
# ------------------------------------------------------------------------------
# =============================================================================
# ğŸ† PROOF & FINAL DELIVERY (KANIT VE NÄ°HAÄ° RAPORLAMA)
# =============================================================================
# Bu modÃ¼l, analiz dÃ¶ngÃ¼sÃ¼nÃ¼ tamamlar ve sonuÃ§larÄ± iki kritik formatta sunar:
#
# 1. ğŸ•µï¸â€â™‚ï¸ Vaka Analizleri / Case Studies (generate_case_studies):
#    - Modelin "GÃ¼venilirliÄŸini" ispatlar.
#    - Son 6 ayda gerÃ§ekleÅŸen arÄ±zalarÄ±, modelin geÃ§miÅŸ tahminleriyle kÄ±yaslar.
#    - Ã‡Ä±ktÄ±: "Model, geÃ§en ay yanan Trafo X'i 'Kritik Risk' olarak Ã¶ngÃ¶rmÃ¼ÅŸ mÃ¼ydÃ¼?"
#      sorusunun cevabÄ±nÄ± iÃ§eren "BaÅŸarÄ±/Hata Karnesi"dir.
#    - Bu tablo, bÃ¼tÃ§e onayÄ± almak iÃ§in en gÃ¼Ã§lÃ¼ kanÄ±ttÄ±r.
#
# 2. ğŸ“‘ Nihai Excel Raporu (create_excel_report):
#    - Projenin resmi teslimat dosyasÄ±dÄ±r.
#    - Ã‡ok sayfalÄ± (Multi-sheet) bir yapÄ±dadÄ±r:
#      a. YÃ¶netici Ã–zeti: Tek bakÄ±ÅŸta filo saÄŸlÄ±ÄŸÄ± ve KPI'lar.
#      b. Acil MÃ¼dahale: BakÄ±m ekiplerinin pazartesi sabahÄ± alacaÄŸÄ± iÅŸ listesi.
#      c. Risk Master: TÃ¼m varlÄ±klarÄ±n detaylÄ± risk dÃ¶kÃ¼mÃ¼ (Top 1000).
# =============================================================================
def create_excel_report(df, crit_chronic, case_studies, logger): 
    """
    TÃ¼m analizleri tek bir Excel dosyasÄ±nda (Multi-Sheet) toplar.
    """
    logger.info("="*60)
    logger.info("[PHASE 3] Excel Raporu OluÅŸturuluyor...")
    
    timestamp = datetime.now().strftime("%Y-%m-%d")
    out_path = os.path.join(REPORT_DIR, f"PoF3_Analiz_Raporu_Final_{timestamp}.xlsx")
    
    risk_col = 'Risk_Sinifi'
    if 'Risk_Class' in df.columns: risk_col = 'Risk_Class'
    
    # Excel Writer BaÅŸlat
    with pd.ExcelWriter(out_path, engine='openpyxl') as writer:
        
        # 1. YÃ–NETÄ°CÄ° Ã–ZETÄ° (KPI Tablosu)
        total = len(df)
        crit_mask = df[risk_col].astype(str).str.contains('KRÄ°T|CRIT', case=False, na=False)
        crit_count = crit_mask.sum()
        
        avg_health = 0
        if 'Health_Score' in df.columns: avg_health = df['Health_Score'].mean()
        
        summary_data = {
            'Metrik': ['Toplam VarlÄ±k SayÄ±sÄ±', 'Kritik Riskli VarlÄ±k SayÄ±sÄ±', 
                       'Kronik ve Kritik (Acil)', 'Filo Ortalama SaÄŸlÄ±k PuanÄ±', 'Rapor Tarihi'],
            'DeÄŸer': [total, crit_count, len(crit_chronic), f"{avg_health:.1f} / 100", timestamp]
        }
        pd.DataFrame(summary_data).to_excel(writer, sheet_name='Yonetici_Ozeti', index=False)
        
        # 2. ACÄ°L MÃœDAHALE LÄ°STESÄ°
        if not crit_chronic.empty:
            crit_chronic.to_excel(writer, sheet_name='Acil_Mudahale_Listesi', index=False)

        # 3. VAKA ANALÄ°ZLERÄ° (KanÄ±t)
        if not case_studies.empty:
            # Sadece Ã¶nemli sÃ¼tunlarÄ± al
            cols = ['cbs_id', 'Ariza_Baslangic_Zamani', 'Ekipman_Tipi', 'Ilce', 
                    'Model_Karari', risk_col, 'PoF_Ensemble_12Ay']
            cols = [c for c in cols if c in case_studies.columns]
            case_studies[cols].to_excel(writer, sheet_name='Model_Dogrulama_Vakalari', index=False)
            
        # 4. RÄ°SK MASTER (TOP 1000)
        # TÃ¼m filoyu basmak yerine en riskli 1000 varlÄ±ÄŸÄ± basar (Dosya boyutu iÃ§in)
        sort_col = 'PoF_Ensemble_12Ay'
        ascending = False # En yÃ¼ksek PoF en Ã¼stte
        
        if sort_col not in df.columns:
            if 'Health_Score' in df.columns:
                sort_col = 'Health_Score'
                ascending = True # En dÃ¼ÅŸÃ¼k saÄŸlÄ±k puanÄ± en Ã¼stte
            else:
                sort_col = df.columns[0] # Fallback

        df.sort_values(sort_col, ascending=ascending).head(1000).to_excel(writer, sheet_name='Risk_Master_Top1000', index=False)
            
    logger.info(f"  ğŸ’¾ Excel Raporu Kaydedildi: {os.path.basename(out_path)}")
    return out_path

# ------------------------------------------------------------------------------
# PHASE 4: POWERPOINT PRESENTATION (YÃ–NETÄ°CÄ° SUNUMU)
# ------------------------------------------------------------------------------
# =============================================================================
# ğŸ“½ï¸ EXECUTIVE PRESENTATION (OTOMATÄ°K SUNUM)
# =============================================================================
# Bu fonksiyon, teknik analiz sonuÃ§larÄ±nÄ± "YÃ¶netim Kurulu" formatÄ±na Ã§evirir.
#
# ğŸ¯ Ã–zellikleri:
#    - Python-PPTX kÃ¼tÃ¼phanesini kullanÄ±r.
#    - Dinamik Ã–zet: Raporun alÄ±ndÄ±ÄŸÄ± gÃ¼nkÃ¼ sayÄ±larÄ± (Kritik, Kronik vb.)
#      slaytlarÄ±n iÃ§ine metin olarak yazar.
#    - GÃ¶rsel Galeri: VISUAL_DIR altÄ±nda Ã¼retilen tÃ¼m grafikleri
#      otomatik olarak yeni slaytlara yerleÅŸtirir.
#
# âš ï¸ Gereksinim:
#    - 'pip install python-pptx' kurulu olmalÄ±dÄ±r.
#    - Kurulu deÄŸilse fonksiyon sessizce Ã§alÄ±ÅŸmayÄ± durdurur (Crash olmaz).
# =============================================================================
def create_pptx_presentation(df, charts, logger):
    """
    Analiz sonuÃ§larÄ±nÄ± ve grafikleri (GeliÅŸmiÅŸ Analitikler dahil) PowerPoint sunumuna dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
    """
    if not HAS_PPTX:
        logger.warning("  âš ï¸ python-pptx kÃ¼tÃ¼phanesi yÃ¼klÃ¼ deÄŸil. PPTX oluÅŸturulamadÄ±.")
        return

    logger.info("="*60)
    logger.info("[PHASE 4] PowerPoint Sunumu OluÅŸturuluyor...")
    
    try:
        prs = Presentation()
    except Exception as e:
        logger.error(f"  âŒ PPTX baÅŸlatÄ±lamadÄ±: {e}")
        return

    timestamp = datetime.now().strftime("%d.%m.%Y")
    
    # --- SLIDE 1: KAPAK ---
    slide = prs.slides.add_slide(prs.slide_layouts[0]) # Title Slide
    title = slide.shapes.title
    subtitle = slide.placeholders[1]
    
    title.text = "VarlÄ±k SaÄŸlÄ±ÄŸÄ± ve Risk Analizi (PoF)"
    subtitle.text = f"YÃ¶netici Ã–zeti Raporu\nRapor Tarihi: {timestamp}\nOluÅŸturan: AI Risk Engine"
    
    # --- SLIDE 2: YÃ–NETÄ°CÄ° Ã–ZETÄ° (METÄ°N) ---
    slide = prs.slides.add_slide(prs.slide_layouts[1]) # Title and Content
    slide.shapes.title.text = "Genel Durum Ã–zeti"
    
    # Ä°statistikleri Hesapla
    total = len(df)
    
    risk_col = 'Risk_Sinifi'
    if 'Risk_Class' in df.columns: risk_col = 'Risk_Class'
    
    crit_count = 0
    if risk_col in df.columns:
        crit_count = df[risk_col].astype(str).str.upper().str.contains('KRÄ°T|CRIT').sum()
        
    chronic_count = 0
    chronic_col = 'Chronic_Flag' if 'Chronic_Flag' in df.columns else 'Kronik_Flag'
    if chronic_col in df.columns:
        chronic_count = (df[chronic_col] == 1).sum()
        
    avg_health = df['Health_Score'].mean() if 'Health_Score' in df.columns else 0

    # Metin Ä°Ã§eriÄŸi
    tf = slide.placeholders[1].text_frame
    tf.text = f"Analiz KapsamÄ±: {total:,} Adet Åebeke VarlÄ±ÄŸÄ±"
    
    p = tf.add_paragraph()
    p.text = f"ğŸš¨ Kritik Riskli VarlÄ±klar: {crit_count:,} adet (%{100*crit_count/total:.1f})"
    p.level = 1
    
    p = tf.add_paragraph()
    p.text = f"ğŸšï¸ Kronik Sorunlu VarlÄ±klar: {chronic_count:,} adet"
    p.level = 1
    
    p = tf.add_paragraph()
    p.text = f"â¤ï¸ Filo Ortalama SaÄŸlÄ±k PuanÄ±: {avg_health:.1f} / 100"
    p.level = 1

    p = tf.add_paragraph()
    p.text = "Ã–neri: 'Acil MÃ¼dahale Listesi'ndeki varlÄ±klar iÃ§in iÅŸ emri oluÅŸturulmalÄ±dÄ±r."
    p.level = 2

    # --- SLIDE 3-X: GRAFÄ°KLER ---
    # Aggregate Risk grafiÄŸi charts sÃ¶zlÃ¼ÄŸÃ¼nde olmayabilir, manuel kontrol ekliyoruz.
    agg_path = os.path.join(VISUAL_DIR, "08_aggregate_risk_by_type.png")
    if os.path.exists(agg_path) and 'aggregate_risk' not in charts:
        charts['aggregate_risk'] = agg_path

    # GÃœNCELLENMÄ°Å HARÄ°TA: Yeni grafikleri buraya ekledik
    slide_mapping = {
        'health_dist': "Filonun SaÄŸlÄ±k Skoru DaÄŸÄ±lÄ±mÄ±",
        'geo_map': "CoÄŸrafi Risk YoÄŸunluk HaritasÄ±",
        'aggregate_risk': "Ekipman Tipine GÃ¶re Risk Analizi",
        'chronic_dist': "Kronik VarlÄ±k Ä°statistikleri",
        
        # --- YENÄ° EKLENENLER (Advanced Diagnostics) ---
        'drivers': "Risk FaktÃ¶rleri (Drivers) Analizi",
        'operational': "Operasyonel Durum Paneli",
        'survival': "VarlÄ±k Ã–mÃ¼r EÄŸrileri (Survival Curves)",
        'health_dash': "DetaylÄ± SaÄŸlÄ±k Analizi Dashboard"
    }
    
    for key, title_text in slide_mapping.items():
        # Grafik sÃ¶zlÃ¼kte var mÄ± VE dosya diskte mevcut mu?
        if key in charts and charts[key] and os.path.exists(charts[key]):
            slide = prs.slides.add_slide(prs.slide_layouts[5]) # Title Only (Resim iÃ§in boÅŸ alan)
            slide.shapes.title.text = title_text
            
            # Resmi Ortala ve YerleÅŸtir
            img_path = charts[key]
            
            left = Inches(0.5) # Biraz daha sola yanaÅŸÄ±k
            top = Inches(1.5)
            height = Inches(5.5) 
            
            try:
                slide.shapes.add_picture(img_path, left, top, height=height)
            except Exception as img_err:
                logger.warning(f"  âš ï¸ Resim eklenirken hata ({key}): {img_err}")

    # Kaydet
    out_path = os.path.join(OUTPUT_DIR, f"PoF3_Yonetici_Sunumu_{timestamp}.pptx")
    try:
        prs.save(out_path)
        logger.info(f"  ğŸ’¾ Sunum Kaydedildi: {os.path.basename(out_path)}")
    except Exception as e:
        logger.error(f"  âŒ Sunum dosyasÄ± kaydedilemedi (Dosya aÃ§Ä±k olabilir mi?): {e}")
# ------------------------------------------------------------------------------
# MAIN ORCHESTRATION
# ------------------------------------------------------------------------------
# =============================================================================
# ğŸš€ MAIN PIPELINE ORCHESTRATION (ANA YÃ–NETÄ°M MERKEZÄ°)
# =============================================================================
# Bu fonksiyon, ham veriden nihai raporlara giden uÃ§tan uca (End-to-End) akÄ±ÅŸÄ± yÃ¶netir.
#
# ğŸ”„ Ä°ÅŸlem AdÄ±mlarÄ± (Process Flow):
#
# 1. ğŸ“¥ Data Ingestion (YÃ¼kleme):
#    - ArÄ±za ve SaÄŸlam ekipman verileri okunur, tarihler parse edilir.
#    - Veri setinin zaman aralÄ±ÄŸÄ± (Start/End Date) otomatik belirlenir.
#
# 2. ğŸ—ï¸ Dataset Construction (Veri Ä°nÅŸasÄ±):
#    - 'build_equipment_master': TÃ¼m varlÄ±klarÄ±n tekil listesi Ã§Ä±karÄ±lÄ±r.
#    - 'add_survival_columns': Sol Kesilme (Left Truncation) ve Ã–mÃ¼r (Duration) hesaplanÄ±r.
#    - 'Chronic & Temporal': ArÄ±za geÃ§miÅŸine dayalÄ± dinamik Ã¶zellikler tÃ¼retilir.
#
# 3. ğŸ›¡ï¸ Global Modeling (GÃ¼venlik AÄŸÄ±):
#    - Veri seti kÃ¼Ã§Ã¼k olan ekipman tipleri (Ã¶rn. "AyÄ±rÄ±cÄ±") iÃ§in tek baÅŸÄ±na model
#      eÄŸitmek risklidir (Overfitting).
#    - Bu adÄ±mda tÃ¼m veriyi kullanan "Global Modeller" (Cox, RSF, ML) eÄŸitilir.
#
# 4. âš™ï¸ Stratified Training (KatmanlÄ± EÄŸitim):
#    - Her ekipman tipi (Trafo, Kesici vb.) iÃ§in dÃ¶ngÃ¼ye girilir.
#    - Karar MekanizmasÄ±:
#      a. Yeterli Veri Var mÄ±? (N > 50, Events > 10) -> O tipe Ã–ZEL model eÄŸit.
#      b. Veri Yetersiz mi? -> GLOBAL modelleri kullan (Fallback).
#
# 5. ğŸ¥ Risk Scoring (Puanlama):
#    - Modellerin Ã¼rettiÄŸi olasÄ±lÄ±klar (PoF), 0-100 arasÄ± "SaÄŸlÄ±k Skoru"na Ã§evrilir.
#    - Kritik ve Kronik varlÄ±klar etiketlenir.
#
# 6. ğŸ•°ï¸ Backtesting (DoÄŸrulama):
#    - Modelin baÅŸarÄ±sÄ±nÄ± Ã¶lÃ§mek iÃ§in geÃ§miÅŸe dÃ¶nÃ¼k (2022-2024) simÃ¼lasyon yapÄ±lÄ±r.
# =============================================================================
def main():
    logger = setup_logger()
    logger.info("ğŸš€ PoF3 Raporlama Motoru BaÅŸlatÄ±lÄ±yor...")
    
    # 1. Dosya KontrolÃ¼ ve YÃ¼kleme
    # pof.py Ã§Ä±ktÄ±sÄ±nÄ± arÄ±yoruz
    risk_path = os.path.join(OUTPUT_DIR, "pof_predictions_final.csv")
    
    if not os.path.exists(risk_path):
        # Fallback: FarklÄ± isimlendirme ihtimaline karÅŸÄ±
        alt_path = os.path.join(OUTPUT_DIR, "risk_equipment_master.csv")
        if os.path.exists(alt_path):
            risk_path = alt_path
        else:
            logger.error(f"[FATAL] SonuÃ§ dosyasÄ± bulunamadÄ±: {risk_path}")
            logger.error("LÃ¼tfen Ã¶nce 'pof.py' (Analiz Motoru) Ã§alÄ±ÅŸtÄ±rÄ±n.")
            return
        
    df = pd.read_csv(risk_path)
    logger.info(f"[LOAD] Risk sonuÃ§larÄ± yÃ¼klendi: {len(df):,} kayÄ±t")
    
    # 2. Veri TemizliÄŸi ve StandartlaÅŸtÄ±rma
    # ID'leri string yap (Merge hatasÄ±nÄ± Ã¶nler)
    df['cbs_id'] = df['cbs_id'].astype(str).str.lower().str.strip()

    # Kolon EÅŸleÅŸtirme (Risk_Sinifi -> Risk_Class)
    if 'Risk_Sinifi' in df.columns and 'Risk_Class' not in df.columns:
        df['Risk_Class'] = df['Risk_Sinifi']
    elif 'Risk_Class' not in df.columns:
        logger.warning("[WARN] Risk kolonu yok. VarsayÄ±lan 'Low' atanÄ±yor.")
        df['Risk_Class'] = 'Low'

    # PoF Kolonunu Garantiye Al (Mevcut kodunuzdaki satÄ±r)
    df = ensure_pof_column(df, logger)

    # =============================================================================
    # ğŸš‘ [FIX] KRONÄ°K VERÄ° KURTARMA OPERASYONU
    # =============================================================================
    # Final dosyada 'Chronic_Flag' yoksa, ara hesaplama dosyasÄ±ndan (ozellikler_zamansal) Ã§eker.
    if 'Chronic_Flag' not in df.columns and 'Kronik_Flag' not in df.columns:
        logger.warning("  âš ï¸ Ana dosyada 'Chronic_Flag' bulunamadÄ±! Ara dosyalardan kurtarÄ±lÄ±yor...")
        
        # Log dosyasÄ±nda gÃ¶rdÃ¼ÄŸÃ¼mÃ¼z ara Ã§Ä±ktÄ± yolu
        chronic_path = os.path.join(INTERMEDIATE_DIR, "ozellikler_zamansal.csv")
        
        if os.path.exists(chronic_path):
            try:
                # Sadece ID ve Flag kolonlarÄ±nÄ± oku (Hafif olsun)
                df_chronic = pd.read_csv(chronic_path, usecols=lambda c: c in ['cbs_id', 'Chronic_Flag', 'Kronik_Flag', 'Fault_Count'])
                
                # ID Standardizasyonu (EÅŸleÅŸme garantisi iÃ§in)
                df_chronic['cbs_id'] = df_chronic['cbs_id'].astype(str).str.lower().str.strip()
                
                # Kolon ismini belirle
                source_col = 'Chronic_Flag' if 'Chronic_Flag' in df_chronic.columns else 'Kronik_Flag'
                
                if source_col:
                    # Ana tablo ile birleÅŸtir
                    df = df.merge(df_chronic[['cbs_id', source_col]], on='cbs_id', how='left')
                    
                    # NaN deÄŸerleri 0 yap (EÅŸleÅŸmeyenler kronik deÄŸildir)
                    df[source_col] = df[source_col].fillna(0).astype(int)
                    
                    # Ä°sim standardÄ±
                    if source_col != 'Chronic_Flag':
                        df['Chronic_Flag'] = df[source_col]
                        
                    count = df['Chronic_Flag'].sum()
                    logger.info(f"  âœ… Kronik verisi baÅŸarÄ±yla eklendi: {count} adet kronik varlÄ±k kurtarÄ±ldÄ±.")
                else:
                    logger.error("  âŒ Ara dosyada da flag bulunamadÄ±.")
            except Exception as e:
                logger.error(f"  âŒ Merge iÅŸlemi baÅŸarÄ±sÄ±z: {e}")
        else:
            logger.error(f"  âŒ Ara dosya bulunamadÄ±: {chronic_path}")
            df['Chronic_Flag'] = 0 # Kod patlamasÄ±n diye dummy
    
    # HÃ¢lÃ¢ yoksa (Kurtarma baÅŸarÄ±sÄ±zsa) dummy oluÅŸtur
    if 'Chronic_Flag' not in df.columns:
        df['Chronic_Flag'] = 0

    # =============================================================================
    # A) Aksiyon Listeleri
    crit_chronic = generate_action_lists(df, logger)
    
    # B) Vaka Analizleri
    case_studies = generate_case_studies(df, logger)
    
    # C) GÃ¶rseller
    charts = generate_visuals(df, logger)
    
    # D) Ã–zel Grafikler
    agg_path = plot_aggregate_risk_by_type(df, logger)
    if agg_path: charts['aggregate_risk'] = agg_path 
    # ... (Mevcut main fonksiyonunun son kÄ±sÄ±mlarÄ±) ...

    # 5. RaporlarÄ± Ãœret
    crit_chronic = generate_action_lists(df, logger)
    case_studies = generate_case_studies(df, logger)
    charts = generate_visuals(df, logger)
    
    # --- YENÄ° EKLENEN GELÄ°ÅMÄ°Å GÃ–RSELLER ---
    # Bu veriler 'intermediate' klasÃ¶rÃ¼ndeki dosyalardan okunacak
    
    # A) Model Girdisi (Drivers ve Survival iÃ§in lazÄ±m)
    model_data_path = os.path.join(INTERMEDIATE_DIR, "model_input_data_full.csv")
    if os.path.exists(model_data_path):
        df_model = pd.read_csv(model_data_path)
        
        # Drivers
        p1 = plot_risk_drivers(df_model, logger)
        if p1: charts['drivers'] = p1
        
        # Survival Curves
        p3 = plot_survival_curves(df_model, logger)
        if p3: charts['survival'] = p3
    
    # B) Operasyonel Dashboard
    p2 = plot_operational_dashboard(logger)
    if p2: charts['operational'] = p2
    
    # C) SaÄŸlÄ±k Dashboard
    p4 = plot_health_dashboard(df, logger)
    if p4: charts['health_dash'] = p4
    # ---------------------------------------

    agg_path = plot_aggregate_risk_by_type(df, logger)
    if agg_path: charts['aggregate_risk'] = agg_path 
    
    # 5. Raporlama
    create_excel_report(df, crit_chronic, case_studies, logger)
    create_pptx_presentation(df, charts, logger)
    
    logger.info("")
    logger.info("="*60)
    logger.info("[SUCCESS] TÃ¼m Raporlama SÃ¼reci BaÅŸarÄ±yla TamamlandÄ±.")
    logger.info(f"ğŸ“‚ Ã‡Ä±ktÄ± KlasÃ¶rÃ¼: {OUTPUT_DIR}")
    logger.info("="*60)

if __name__ == "__main__":
    main()